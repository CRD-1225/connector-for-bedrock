{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy llama3 to Inf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating packages\n",
    "%pip install -U sagemaker\n",
    "%pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = \"HuggingfaceExecuteRole\"\n",
    "region_name = \"us-west-2\"\n",
    "djl_framework=\"djl-neuronx\"\n",
    "djl_version=\"0.27.0\"\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "role = iam_client.get_role(RoleName=role_name)['Role']['Arn']\n",
    "sess = sagemaker.Session(boto_session=boto3.Session(profile_name=\"default\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.entryPoint=djl_python.transformers_neuronx\n",
    "option.model_id=meta-llama/Meta-Llama-3-8B-Instruct\n",
    "option.max_rolling_batch_size=8\n",
    "option.tensor_parallel_degree=24\n",
    "option.n_positions=512\n",
    "option.rolling_batch=auto\n",
    "option.enable_mixed_precision_accumulation=true\n",
    "option.enable_streaming=true\n",
    "option.output_formatter=jsonlines\n",
    "option.model_loading_timeout=3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir mymodel\n",
    "mv serving.properties mymodel/\n",
    "tar czvf mymodel.tar.gz mymodel/\n",
    "rm -rf mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_code_prefix = \"llama3-8b-instruct-lmi/code\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "code_artifact = sess.upload_data(\"mymodel.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- &gt; {code_artifact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = image_uris.retrieve(\n",
    "        framework=djl_framework,\n",
    "        region=region_name,\n",
    "        version=djl_version\n",
    "    )\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(image_uri=image_uri, model_data=code_artifact, role=role)\n",
    "instance_type = \"ml.inf2.8xlarge\"\n",
    "endpoint_name = \"llama3-8b-instruct-model\" \n",
    "# sagemaker.utils.name_from_base(\"llama3-8b-instruct-model\")\n",
    "\n",
    "model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             container_startup_health_check_timeout=3600,\n",
    "             volume_size=512,\n",
    "             region=region_name,\n",
    "             endpoint_name=endpoint_name)\n",
    "region_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
